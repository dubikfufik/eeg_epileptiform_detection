{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43fe1ec4-002f-4d3f-9c9c-cc14afb1d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import resample\n",
    "from utils_pipeline import Pipeline\n",
    "from preprocessing_library import FFT, Slice, Magnitude, Log10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b8a62e-7a94-46cf-a5a0-e515453d09dc",
   "metadata": {},
   "source": [
    "### Constructing the dictionary with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90f3b17-a118-4ccf-8613-10b98e688dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    @staticmethod\n",
    "    def merge(segments):\n",
    "        \"\"\"\n",
    "        :param segments: list of overlapping intervals with same label, segment[i][0] - start, segment[i][1] - end\n",
    "        :return: list of intervals with no overlaps\n",
    "        \"\"\"\n",
    "        merged = []\n",
    "        segments.sort(key=lambda x: x[0])\n",
    "\n",
    "        for segment in segments:\n",
    "            if not merged or segment[0] > merged[-1][1]:\n",
    "                merged.append(segment)\n",
    "            else:\n",
    "                merged[-1][1] = segment[1]\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def labeling(self, intervals: list[list[float], int]):\n",
    "        \"\"\"\n",
    "        :param intervals: list of intervals where intervals[i][0] - start intervals[i][1] - end intervals[i][2] - label\n",
    "        :return: labels - dictionary, keys - labels, values - intervals\n",
    "        \"\"\"\n",
    "        labels = {}\n",
    "\n",
    "        for interval in intervals:\n",
    "            if interval[-1] not in labels:\n",
    "                labels[interval[-1]] = [interval[0]]\n",
    "            else:\n",
    "                labels[interval[-1]].append(interval[0])\n",
    "\n",
    "        # print(labels)\n",
    "        for key in labels:\n",
    "            labels[key] = self.merge(labels[key])\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def apply_one_file(self, file_path):\n",
    "        \"\"\"\n",
    "        :params: file_path - path to a single file\n",
    "        :return: result - dictionary with the following structure: file_name -> channel -> lable -> intervals with no overlaps\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        dct = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            for node in file.readlines():\n",
    "                node = node[:-1]\n",
    "\n",
    "                node = node.split(',')\n",
    "\n",
    "                if int(node[0]) not in dct:\n",
    "                    dct[int(node[0])] = [[[float(node[1]), float(node[2])], int(node[3])]]\n",
    "                else:\n",
    "                    dct[int(node[0])].append([[float(node[1]), float(node[2])], int(node[3])])\n",
    "\n",
    "            for key in dct:\n",
    "                dct[key] = self.labeling(dct[key])\n",
    "    \n",
    "            result[file_path[:-4]] = dct\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def apply_dataset(self):\n",
    "        \"\"\"\n",
    "        apply the labeling to the whole directory\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        \n",
    "        for root, dirs, files in os.walk(\"/Users/konstantin/Desktop/TUEV_data/edf/train\", topdown=True):\n",
    "            for name in files:\n",
    "                if name.endswith('.rec'):\n",
    "                    file_path = os.path.join(root, name)\n",
    "\n",
    "                    dct = {}\n",
    "                    \"\"\"\n",
    "                    node[0] - chanel\n",
    "                    node[1] - start\n",
    "                    node[2] - end\n",
    "                    node[3] - label\n",
    "                    \"\"\"\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        for node in file.readlines():\n",
    "                            node = node[:-1]\n",
    "\n",
    "                            node = node.split(',')\n",
    "\n",
    "                            if int(node[0]) not in dct:\n",
    "                                dct[int(node[0])] = [[[round(float(node[1]), 4), round(float(node[2]), 4)], int(node[3])]]\n",
    "                            else:\n",
    "                                dct[int(node[0])].append([[round(float(node[1]), 4), round(float(node[2]), 4)], int(node[3])])\n",
    "\n",
    "                    for key in dct:\n",
    "                        dct[key] = self.labeling(dct[key])\n",
    "\n",
    "                    result[file_path[:-4]] = dct\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bb06e-00c5-417a-8a78-891ed673defa",
   "metadata": {},
   "source": [
    "### Analysing the dictionary with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144325d6-dbb7-4ab7-84ae-ee7437a1a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dct = Preprocess().apply_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6eb162d-1f32-4520-bdba-0e7218d4f91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17234\n",
      "2228\n"
     ]
    }
   ],
   "source": [
    "cnt_int = 0\n",
    "cnt_float = 0\n",
    "\n",
    "for file_name in label_dct.keys():\n",
    "    for channel in sorted(label_dct[file_name].keys()):\n",
    "        for label in sorted(label_dct[file_name][channel].keys()):\n",
    "            for interval in label_dct[file_name][channel][label]:\n",
    "                if (interval[1] - interval[0]) % 1 == 0:\n",
    "                    cnt_int += 1\n",
    "                else:\n",
    "                    cnt_float += 1\n",
    "\n",
    "print(cnt_int)\n",
    "print(cnt_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc440836-8d4d-46ef-99f6-fa9e3b8745c9",
   "metadata": {},
   "source": [
    "### Constructing numpy files for a single edf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8e40d5-d1f6-4061-9c56-e6d7c779eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/konstantin/Desktop/TUEV_data/edf/train/aaaaablw/aaaaablw_00000001': {6: {6: [[29.1,\n",
       "     38.1],\n",
       "    [57.7, 65.7]]},\n",
       "  9: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  20: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  15: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  1: {6: [[29.1, 38.1]]},\n",
       "  11: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  2: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  21: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  14: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  10: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  12: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  19: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  8: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  0: {6: [[29.1, 38.1]]},\n",
       "  13: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  5: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  16: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  18: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  3: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  17: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  7: {6: [[29.1, 38.1], [57.7, 65.7]]},\n",
       "  4: {6: [[29.1, 38.1], [57.7, 65.7]]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path_rec = '/Users/konstantin/Desktop/TUEV_data/edf/train/aaaaablw/aaaaablw_00000001.rec'\n",
    "single_file_dct = Preprocess().apply_one_file(test_file_path_rec)\n",
    "single_file_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d8f7b-fd7c-4bc1-aab2-1b67543655dd",
   "metadata": {},
   "source": [
    "### Extracting signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b60f9f5-47b4-47c4-bb0c-25ea6de61695",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.read_csv('parameters.csv', index_col=['parameter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171e8193-548d-4489-b846-e498da37f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signal(f, signal_labels, electrode_name, start, stop):\n",
    "    \"\"\"\n",
    "    f - opened edf file.\n",
    "    signal_labels - list of signals.\n",
    "    electrode_name - the name of electrode.\n",
    "    start - start of the window in seconds.\n",
    "    stop - end of the window in seconds.\n",
    "    \"\"\"\n",
    "    tuh_label = [s for s in signal_labels if 'EEG ' + electrode_name + '-' in s]\n",
    "    if len(tuh_label) > 1:\n",
    "        print(tuh_label)\n",
    "        exit('Multiple electrodes found with the same string! Abort')\n",
    "        \n",
    "    channel = signal_labels.index(tuh_label[0])\n",
    "    signal = np.array(f.readSignal(channel))\n",
    "\n",
    "    return signal[start:stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0f461-44fb-482f-bd83-f4af2a7acc9f",
   "metadata": {},
   "source": [
    "### Constructing FFT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307d0747-425a-4bb6-996d-fcb0a0df4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fft(window_start, window_end, window_step, channel,\n",
    "                               fft_min_freq, fft_max_freq, sampling_frequency, file_path):\n",
    "    \"\"\"\n",
    "    Split an interval into 1 second intervals with 0.5 second overlap, applying FFT.\n",
    "    \n",
    "    parmas:\n",
    "    window_start - the beginning of interval in seconds.\n",
    "    window_end - the end of interval in seconds.\n",
    "    window_step - the overlap in seconds.\n",
    "    channel - \n",
    "    fft_min_freq - the min frequency.\n",
    "    fft_max_freq - the max ferquency.\n",
    "    sampling_ferquency - the frequency of the edf file.\n",
    "    file_path - the path to the edf file.\n",
    "    \n",
    "    return:\n",
    "    np.array - interval splitted into 1 secons segments with 0.5 second overlap, with FFT applied.\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([FFT(), Slice(fft_min_freq, fft_max_freq), Magnitude(), Log10()])\n",
    "    \n",
    "    start, step = int(np.floor(window_start * sampling_frequency)), int(np.floor(window_step * sampling_frequency))\n",
    "    stop = start + step\n",
    "\n",
    "    lst = file_path.split('/')\n",
    "    file_name = lst[-1][:-4]\n",
    "    fft_data = []\n",
    "\n",
    "    montage = str(parameters.loc['montage']['value'])\n",
    "    montage_list = re.split(';', montage)\n",
    "    electrode_list = re.split('-', montage_list[channel])\n",
    "\n",
    "    f = pyedflib.EdfReader(file_path)\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    \n",
    "    while stop <= window_end * sampling_frequency:\n",
    "        extracted_signal_from_electrode_1 = extract_signal(f, signal_labels, electrode_list[0], start, stop)\n",
    "        extracted_signal_from_electrode_2 = extract_signal(f, signal_labels, electrode_list[1], start, stop)\n",
    "        \n",
    "        signal_window = np.array(extracted_signal_from_electrode_1-extracted_signal_from_electrode_2)\n",
    "        fft_window = pipeline.apply(signal_window)\n",
    "        \n",
    "        fft_data.append(fft_window)\n",
    "        start, stop = start + step, stop + step\n",
    "        # print(fft_data)\n",
    "    \n",
    "    f._close()\n",
    "    del f\n",
    "    \n",
    "    return np.array(fft_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0577eab-3516-495a-8ad4-0a84ffb58cc8",
   "metadata": {},
   "source": [
    "### A single file usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ac37ce-1fca-4e47-ad32-5f59ae4070cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr: [[1.71065759 1.63976    0.7138609  ... 1.55237657 1.50406547 1.90812192]\n",
      " [2.1504314  1.75372405 1.93814755 ... 1.94654594 1.88536572 1.17318448]\n",
      " [2.42635049 1.64645036 2.12363506 ... 1.09739108 1.66243951 1.60798202]\n",
      " ...\n",
      " [2.17775443 2.04387071 1.9346262  ... 1.92730655 1.3667573  2.00884202]\n",
      " [2.24846638 2.50624815 1.5401735  ... 1.79142518 1.87465735 1.69932475]\n",
      " [2.20585812 1.91174881 1.93668347 ... 1.58703052 1.08450881 1.64234488]],\n",
      "len(arr): 18,\n",
      "len(arr[0]): 96\n"
     ]
    }
   ],
   "source": [
    "test_file_path_edf = '/Users/konstantin/Desktop/TUEV_data/edf/train/aaaaablw/aaaaablw_00000001.edf'\n",
    "arr = convert_to_fft(29.1, 38.1, 0.5, 0, 1, 96, 250, test_file_path_edf)\n",
    "print(f'arr: {arr},\\nlen(arr): {len(arr)},\\nlen(arr[0]): {len(arr[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee8513-a373-4d16-9550-adfafdcb7635",
   "metadata": {},
   "source": [
    "### Multiple-files usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa246105-d050-4473-8d86-c504a1282423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/konstantin/Desktop/TUEV_data/edf/train/aaaaablw/aaaaablw_00000001\n",
      "/Users/konstantin/Desktop/TUEV_data/edf/train/aaaaaevo/aaaaaevo_00000001\n",
      "/Users/konstantin/Desktop/TUEV_data/edf/train/aaaaaeyk/aaaaaeyk_00000001\n"
     ]
    }
   ],
   "source": [
    "unique_id = 0\n",
    "for file_name in list(label_dct.keys())[:3]: # constructing the numpy files for the first 3 files\n",
    "    print(file_name)\n",
    "    for channel in range(22): \n",
    "        try: # sometimes there is no data about a channel\n",
    "            for label in label_dct[file_name][channel]:\n",
    "                for index, interval in enumerate(label_dct[file_name][channel][label]):\n",
    "                    result_file_name = file_name + '_channel_' + str(channel) + '_label_' + str(label) + '_interval_id_' + str(index) + '_unique_id_' + str(unique_id)\n",
    "                    unique_id += 1\n",
    "\n",
    "                    arr = convert_to_fft(interval[0], interval[1], 0.5, channel, 1, 96, 250, file_name + '.edf')\n",
    "                    np.save(result_file_name, arr)\n",
    "        except KeyError:\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34a4ef-8f52-4dcf-96b6-765bb099b40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
